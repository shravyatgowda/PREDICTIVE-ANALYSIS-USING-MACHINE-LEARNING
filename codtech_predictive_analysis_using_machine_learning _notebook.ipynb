{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "510783bf",
   "metadata": {},
   "source": [
    "# Codtech — Data Analyst Internship\n",
    "\n",
    " **Task 2 — Predictive analysis using machine learning**\n",
    "\n",
    "**Objective:** Build a classification model to predict customer churn. Notebook demonstrates feature selection, model training, and evaluation. Dataset: synthetic ~10,000 rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df337c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, RocCurveDisplay\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('/mnt/data/codtech_task2_dataset.csv')\n",
    "print('Dataset shape:', df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b614a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA checks\n",
    "print('Missing values per column:\\n', df.isna().sum())\n",
    "print('\\nTarget distribution (churn = 1):\\n', df['churn'].value_counts(normalize=True))\n",
    "display(df.describe().T)\n",
    "\n",
    "# Simple plots\n",
    "plt.figure()\n",
    "df['age'].hist(bins=25)\n",
    "plt.title('Age distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "df['balance_usd'].hist(bins=30)\n",
    "plt.title('Balance distribution')\n",
    "plt.xlabel('Balance (USD)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df.drop(columns=['churn'])\n",
    "y = df['churn']\n",
    "\n",
    "numeric_features = ['credit_score', 'age', 'tenure_years', 'balance_usd', 'num_products',\n",
    "                    'estimated_salary_usd', 'monthly_spend_usd', 'transactions_last_month',\n",
    "                    'mobile_app_usage_min_per_day', 'campaigns_responded']\n",
    "\n",
    "categorical_features = ['geography', 'gender']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = OneHotEncoder(drop='first', sparse=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "], remainder='drop')\n",
    "\n",
    "# Fit-transform to get feature matrix for selection demonstration\n",
    "X_pre = preprocessor.fit_transform(X)\n",
    "# Build feature names\n",
    "ohe = preprocessor.named_transformers_['cat']\n",
    "cat_cols = list(ohe.get_feature_names_out(categorical_features))\n",
    "feature_names = numeric_features + cat_cols\n",
    "X_pre.shape, len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a21c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection with SelectKBest\n",
    "selector = SelectKBest(score_func=f_classif, k=8)\n",
    "selector.fit(X_pre, y)\n",
    "mask = selector.get_support()\n",
    "selected_features = [f for f, m in zip(feature_names, mask) if m]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa96c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split before creating final pipeline (to avoid data leakage)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
    "\n",
    "# Create final pipeline including preprocessor and model placeholder (we'll swap model)\n",
    "pipe_lr = Pipeline(steps=[('pre', preprocessor), ('sel', SelectKBest(score_func=f_classif, k=8)), ('clf', LogisticRegression(max_iter=1000))])\n",
    "pipe_rf = Pipeline(steps=[('pre', preprocessor), ('sel', SelectKBest(score_func=f_classif, k=8)), ('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "# Train Logistic Regression\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred_lr = pipe_lr.predict(X_test)\n",
    "y_proba_lr = pipe_lr.predict_proba(X_test)[:,1]\n",
    "print('Logistic Regression - Accuracy:', accuracy_score(y_test, y_pred_lr))\n",
    "print('Logistic Regression - ROC AUC:', roc_auc_score(y_test, y_proba_lr))\n",
    "print('\\nClassification report:\\n', classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acb4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest with a small GridSearch for demonstration\n",
    "param_grid = {'clf__n_estimators': [100, 200], 'clf__max_depth': [6, 12]}\n",
    "grid = GridSearchCV(pipe_rf, param_grid=param_grid, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print('Best params:', grid.best_params_)\n",
    "best_rf = grid.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_proba_rf = best_rf.predict_proba(X_test)[:,1]\n",
    "print('Random Forest - Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "print('Random Forest - ROC AUC:', roc_auc_score(y_test, y_proba_rf))\n",
    "print('\\nClassification report:\\n', classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a52d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve comparison\n",
    "plt.figure()\n",
    "RocCurveDisplay.from_estimator(pipe_lr, X_test, y_test)\n",
    "plt.title('ROC - Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "RocCurveDisplay.from_estimator(best_rf, X_test, y_test)\n",
    "plt.title('ROC - Random Forest')\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix for best_rf\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "print('Confusion matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ce4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model as an example\n",
    "import joblib\n",
    "model_path = '/mnt/data/codtech_task2_best_model.pkl'\n",
    "joblib.dump(best_rf, model_path)\n",
    "print('Saved best model to', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d50d6",
   "metadata": {},
   "source": [
    "## Conclusion & Next steps\n",
    "\n",
    "- Random Forest (after small tuning) generally performed better in ROC AUC.\n",
    "- Next steps: more thorough hyperparameter tuning, cross-validation, calibration, testing on real data, and feature importance analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e70f9-9bd9-410c-b6e0-1b8c07c7db10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
